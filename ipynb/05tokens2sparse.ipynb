{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List\n",
    "import gensim\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Constants for file path names\n",
    "TOKENFILE = '../intermediate/titleabstract_tokens.txt'\n",
    "TERMDICTFILE = '../models/titleabstract.dict'\n",
    "TERMCORPUSFILE = '../models/titleabstract_corpus.mm'\n",
    "TERMTFIDFMODELFILE = '../models/titleabstract.tfidf_model'\n",
    "TERMTFIDFFILE = '../models/titleabstract_tfidf.mm'\n",
    "CLASSFILE = '../intermediate/classifications_ipc.txt'\n",
    "CLASSDICTFILE = '../models/classifications.dict'\n",
    "CLASSCORPUSFILE = '../models/classifications_corpus.mm'\n",
    "CLASSTFIDFMODELFILE = '../models/classifications.tfidf_model'\n",
    "CLASSTFIDFFILE = '../models/classifications_tfidf.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(infile: str) -> Iterator[List[str]]:\n",
    "    '''Yield tokens split on whitespace from each newline terminated string(doc) in file (with newline stripped)\n",
    "    Parameters\n",
    "        infile: full path string to file containing strings\n",
    "    Returns\n",
    "        each string with newline stripped\n",
    "    '''\n",
    "    with open(infile, 'r', encoding='utf-8') as inf:\n",
    "        for line in inf:\n",
    "            yield line.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens2sparsevecs(infile: str, dictname: gensim.corpora.dictionary.Dictionary):\n",
    "    return (dictname.doc2bow(tokens) for tokens in get_tokens(infile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corpus(filename: str, vecs, dictname: gensim.corpora.dictionary.Dictionary) -> None:\n",
    "    '''Save a corpus of vectors in Matrix Market format\n",
    "    Parameters\n",
    "        filename: full path to file to save\n",
    "        vecs: corpus to save\n",
    "        dictname: gensim dictionary with id, word pairs\n",
    "    '''\n",
    "    corpora.MmCorpus.serialize(filename, vecs, id2word=dictname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_dict = corpora.Dictionary(get_tokens(TOKENFILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_dict.save(TERMDICTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_corpus(TERMCORPUSFILE, \n",
    "            tokens2sparsevecs(TOKENFILE, terms_dict), \n",
    "            terms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = models.TfidfModel(corpus=tokens2sparsevecs(TOKENFILE, terms_dict), \n",
    "                                id2word=terms_dict, \n",
    "                                normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.save(TERMTFIDFMODELFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_sv = tfidf_model[tokens2sparsevecs(TOKENFILE, terms_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_corpus(TERMTFIDFFILE, \n",
    "            tfidf_sv, \n",
    "            terms_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Classification Codes into Vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_dict = corpora.Dictionary(get_tokens(CLASSFILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_dict.save(CLASSDICTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_corpus(CLASSCORPUSFILE, \n",
    "            tokens2sparsevecs(CLASSFILE, cl_dict),\n",
    "            cl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model_cl = models.TfidfModel(corpus=tokens2sparsevecs(CLASSFILE, cl_dict), \n",
    "                                   id2word=cl_dict, \n",
    "                                   normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model_cl.save(CLASSTFIDFMODELFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_sv_cl = tfidf_model[tokens2sparsevecs(CLASSFILE, cl_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_corpus(CLASSTFIDFFILE,\n",
    "            tfidf_sv_cl,\n",
    "            cl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
